ğŸš€ Contract Intelligence RAG System â€” README.md
ğŸ“˜ Contract Intelligence RAG System

A fully-functional LLM-powered Contract Intelligence System built using:

FastAPI (Backend Framework)

FAISS (Vector Database)

HuggingFace Embeddings (intfloat/multilingual-e5-base)

Groq Llama-3.3-70B (LLM for Q&A, Extraction, Audit)

PostgreSQL (Document Storage)

PyPDF2 (PDF Text Extraction)

This system supports:

âœ… Contract Ingestion
âœ… Contract Information Extraction (structured fields)
âœ… RAG-based Question Answering with citations
âœ… Contract Risk Auditing (clause severity, evidence, remediation)
âœ… SSE Streaming for real-time answers
âœ… Admin Metrics + Health Check

ğŸ§± Architecture Overview
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   PDF Upload     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Ingest Service  â”‚
          â”‚ - PyPDF2         â”‚
          â”‚ - Chunking       â”‚
          â”‚ - Metadata       â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                    â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ PostgreSQL DB   â”‚   â”‚ FAISS Vector DB â”‚
 â”‚ (full text)     â”‚   â”‚ (embeddings)    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ RAG Engine + LLM   â”‚
         â”‚ - Groq Llama-70B   â”‚
         â”‚ - Context Builder  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ /ask     â€“ Q&A + citations       â”‚
 â”‚ /extract â€“ structured fields     â”‚
 â”‚ /audit   â€“ contract risk analysisâ”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ›  Tech Stack
Component	Technology
Backend	FastAPI
LLM	Groq Llama-3.3-70B
Embeddings	intfloat/multilingual-e5-base
Vector DB	FAISS
Database	PostgreSQL
PDF Parsing	PyPDF2
Streaming	SSE (Server Sent Events)
ğŸ“¦ Project Setup
1. Clone Repo
git clone https://github.com/<username>/<repo>.git
cd contract-intelligence

2. Create Virtual Environment
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows

3. Install Requirements
pip install -r requirements.txt

4. Setup PostgreSQL

Create a database:

CREATE DATABASE contractdb;

5. Create .env File

Inside project root:

POSTGRES_URL=postgresql://postgres:<password>@localhost:5432/contractdb
GROQ_API_KEY=xxxxxxxxxxxxxxxxxxxx

â–¶ï¸ Run FastAPI Server
uvicorn app.main:app --reload


Server will start at:

ğŸ‘‰ http://127.0.0.1:8000

ğŸ‘‰ Docs: http://127.0.0.1:8000/docs

ğŸ³ Docker Setup
Build Image
docker build -t contract-intel .

Run Container
docker run -p 8000:8000 --env-file .env contract-intel

ğŸ”Œ API Endpoints
âœ” /ingest â€” Upload + Process Contract

Method: POST
Type: multipart/form-data (PDF)

Stores:

full text in PostgreSQL

chunk embeddings to FAISS

ğŸ“„ Code Ref: ingest.py

Example CURL
curl -X POST "http://localhost:8000/ingest/" \
  -F "file=@sample.pdf"

âœ” /ask â€” RAG Question Answering

Returns:

LLM answer

citations (page, char start/end)

ğŸ“„ Code Ref: ask.py

Example CURL
curl -X POST "http://localhost:8000/ask/" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the governing law?"}'

âœ” /ask/stream â€” Streaming RAG Answer (SSE)
curl http://localhost:8000/ask/stream?question=What+is+the+payment+term

âœ” /extract â€” Extract Structured Fields

ğŸ“„ Code Ref: extract.py

Extracts:

parties

effective_date

governing_law

term

payment terms

indemnity

liability cap

signatories

auto renewal

confidentiality

Example CURL
curl -X POST "http://localhost:8000/extract/" \
  -d "document_id=1"

âœ” /audit â€” Contract Risk Analysis

ğŸ“„ Code Ref: audit.py

Returns risk JSON:

severity

clause

evidence text

char indexes

page number

remediation

confidence

Example CURL
curl -X POST "http://localhost:8000/audit/" \
  -H "Content-Type: application/json" \
  -d '{"document_id": 1}'

âœ” /admin/metrics

Shows API usage counts:

ingest_count

extract_count

ask_count

audit_count

uptime

âœ” /healthz

Health check endpoint
ğŸ“„ Code Ref: admin.py

ğŸ“‚ Project Structure
app/
â”‚â”€â”€ api/
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ ask.py
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ audit.py
â”‚   â””â”€â”€ admin.py
â”‚
â”‚â”€â”€ services/
â”‚   â”œâ”€â”€ rag_engine.py
â”‚   â”œâ”€â”€ text_splitter.py
â”‚   â”œâ”€â”€ llm_extractor.py
â”‚
â”‚â”€â”€ db/
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ crud.py
â”‚   â”œâ”€â”€ connection.py
â”‚
â”‚â”€â”€ main.py
â”‚â”€â”€ config.py

âš ï¸ Trade-offs & Decisions
1. FAISS over PGVector

âœ” Faster
âœ” Lightweight
âœ” Local index
âœ– Not distributed horizontally

2. Groq Llama-3.3-70B

âœ” Extremely fast inference
âœ” High accuracy
âœ– Requires API key

3. PyPDF2 for extraction

âœ” Simple
âœ– Less accurate for complex PDFs (tables, scanned docs)

4. Character Index Based Citations

âœ” Exact pinpointing
âœ” Helpful for UI highlighting
âœ– Dependent on clean PDF text

5. JSON Schema Force Prompts

âœ” Reliable outputs
âœ– Needs fallback JSON cleaning

ğŸ§ª Testing Tips
Reset vectorstore
rm -rf vectorstore

Reset DB
DROP TABLE documents;

ğŸ¯ Conclusion

This system is a full production-grade Contract Intelligence pipeline supporting:

Vector-based retrieval

LLM Q&A

Structured extraction

Risk auditing

Streaming answers

Monitoring

It is scalable, modular, and easily deployable with Docker.
